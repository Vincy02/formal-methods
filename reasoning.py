import pm4py
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
import os

FILENAME = "BPI_Challenge_2013_closed_problems.xes.gz"
load_dotenv(override=True)
API_KEY = os.getenv('OPENAI_API_KEY')

client = OpenAI(api_key=API_KEY)

def extract_statistics_for_llm(log):
    print("Statistical processing from log file...")
    df = pm4py.convert_to_dataframe(log)
    
    # 1. Time Statistics
    case_durations = []
    for case_id, group in df.groupby("case:concept:name"):
        start = group["time:timestamp"].min()
        end = group["time:timestamp"].max()
        duration_days = (end - start).total_seconds() / 86400
        case_durations.append(duration_days)
    
    avg_duration = sum(case_durations) / len(case_durations)
    max_duration = max(case_durations)
    
    # 2. Variants
    variants = pm4py.get_variants_as_tuples(log)
    
    # Are we working with numbers or lists?
    first_val = next(iter(variants.values())) if variants else 0
    
    top_3_data = []
    if isinstance(first_val, int):
        # CASE A: PM4Py directly returns the number (Count)
        sorted_variants = sorted(variants.items(), key=lambda x: x[1], reverse=True)
        top_3_data = sorted_variants[:3] 
    else:
        # CASE B: PM4Py returns a list of tracks
        sorted_variants = sorted(variants.items(), key=lambda x: len(x[1]), reverse=True)
        top_3_data = [(k, len(v)) for k, v in sorted_variants[:3]]
    
    # 3. Resources (Who works the hardest)
    top_resources = df['org:resource'].value_counts().head(3).to_dict()
    
    # Context text for LLM
    context_text = f"""
    DATASET SUMMARY:
    - Total Cases: {len(case_durations)}
    - Average Resolution Time: {avg_duration:.2f} days
    - Max Resolution Time: {max_duration:.2f} days
    
    TOP 3 PROCESS PATHS (Most frequent sequences of activities):
    1. {top_3_data[0][0]} (Occurs {top_3_data[0][1]} times)
    2. {top_3_data[1][0]} (Occurs {top_3_data[1][1]} times)
    3. {top_3_data[2][0]} (Occurs {top_3_data[2][1]} times)
    
    TOP RESOURCES (Most active users):
    {top_resources}
    """
    return context_text

def ask_gpt(context_text):
    print("Send request to OpenAI...")
    
    prompt = f"""
    You are a Process Mining Expert analyzing an Incident Management log (Volvo IT).
    Here is the statistical summary of the process data:
    
    {context_text}
    
    Based on this data, please generate a short report covering:
    1. **Performance Analysis**: Is the average time acceptable? Why is there such a huge gap between average and max time?
    2. **Anomalies**: Identify potential problems in the process flow or resources.
    3. **Recommendations**: Suggest 2 concrete actions to optimize the process.
    
    Keep the answer professional and concise.
    """
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful data scientist assistant."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )
    
    return response.choices[0].message.content

# --- MAIN EXECUTION --- #
if __name__ == "__main__":
    log = pm4py.read_xes(FILENAME)

    context = extract_statistics_for_llm(log)
    print("\n--- Extract statistics for context ---")
    print(context)
    
    if API_KEY != "":
        report = ask_gpt(context)
        print("\n" + "="*30)
        print(" REPORT GENERATED BY AI ")
        print("="*30)
        print(report)
        
        # Saving the report
        with open("ai_report.md", "w") as f:
            f.write(report)
            print("\nReport saved in: 'ai_report.md'")
    else:
        print("\nERROR: API Key missing in .env file or script.")